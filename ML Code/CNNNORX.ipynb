{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Label Mapping: {'Gesture A': 0, 'Gesture D': 1, 'Gesture L': 2, 'Gesture U': 3}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# 定义数据清理函数\n",
    "def clean_data(data):\n",
    "    cleaned_data = []\n",
    "    for i, row in data.iterrows():\n",
    "        try:\n",
    "            x = literal_eval(row[1])\n",
    "            y = literal_eval(row[2])\n",
    "            z = literal_eval(row[3])\n",
    "            cleaned_data.append([row[0], x, y, z])\n",
    "        except (ValueError, SyntaxError) as e:\n",
    "            print(f\"Skipping line {i + 1}: {e}\")\n",
    "    return pd.DataFrame(cleaned_data, columns=['label', 'x', 'y', 'z'])\n",
    "\n",
    "# 数据增强函数\n",
    "def augment_data(data, labels):\n",
    "    augmented_data = []\n",
    "    augmented_labels = []\n",
    "    for d, label in zip(data, labels):\n",
    "        augmented_data.append(d)\n",
    "        augmented_labels.append(label)\n",
    "        # Add noise\n",
    "        noise = np.random.normal(0, 0.1, d.shape)\n",
    "        augmented_data.append(d + noise)\n",
    "        augmented_labels.append(label)\n",
    "        # Flip data\n",
    "        augmented_data.append(np.flip(d, axis=0))\n",
    "        augmented_labels.append(label)\n",
    "    return np.array(augmented_data), np.array(augmented_labels)\n",
    "\n",
    "# 读取数据并清理\n",
    "data = pd.read_csv('E:/TFM/gesturesNOXR.csv', header=None)\n",
    "cleaned_data = clean_data(data)\n",
    "\n",
    "# 读取老师的数据并清理\n",
    "teacher_data = pd.read_csv('E:/TFM/gesturesProfeNOXR.csv', header=None)\n",
    "cleaned_teacher_data = clean_data(teacher_data)\n",
    "\n",
    "# 将你的数据和老师的数据分开处理\n",
    "train_labels = cleaned_data['label']\n",
    "train_x_data = cleaned_data['x']\n",
    "train_y_data = cleaned_data['y']\n",
    "train_z_data = cleaned_data['z']\n",
    "\n",
    "test_labels = cleaned_teacher_data['label']\n",
    "test_x_data = cleaned_teacher_data['x']\n",
    "test_y_data = cleaned_teacher_data['y']\n",
    "test_z_data = cleaned_teacher_data['z']\n",
    "\n",
    "# 合并 x, y, z 数据\n",
    "def merge_data(x_data, y_data, z_data):\n",
    "    X = []\n",
    "    for x, y, z in zip(x_data, y_data, z_data):\n",
    "        combined = np.array([x, y, z]).T\n",
    "        X.append(combined.tolist())\n",
    "    return X\n",
    "\n",
    "train_X = merge_data(train_x_data, train_y_data, train_z_data)\n",
    "test_X = merge_data(test_x_data, test_y_data, test_z_data)\n",
    "\n",
    "# 填充序列到相同长度\n",
    "max_length = max([len(seq) for seq in train_X + test_X])\n",
    "train_X = pad_sequences(train_X, maxlen=max_length, padding='post', dtype='float32')\n",
    "test_X = pad_sequences(test_X, maxlen=max_length, padding='post', dtype='float32')\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_X.reshape(-1, train_X.shape[-1])).reshape(train_X.shape)\n",
    "test_X_scaled = scaler.transform(test_X.reshape(-1, test_X.shape[-1])).reshape(test_X.shape)\n",
    "\n",
    "# 转换标签为 one-hot 编码\n",
    "label_encoder = LabelEncoder()\n",
    "train_y = label_encoder.fit_transform(train_labels)\n",
    "train_y_one_hot = to_categorical(train_y)\n",
    "\n",
    "test_y = label_encoder.transform(test_labels)\n",
    "test_y_one_hot = to_categorical(test_y)\n",
    "\n",
    "# 打印标签编码器的类和标签的对应关系\n",
    "label_map = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Mapping:\", label_map)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "18/18 [==============================] - 3s 38ms/step - loss: 1.3193 - accuracy: 0.3308 - val_loss: 1.2007 - val_accuracy: 0.4582 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0851 - accuracy: 0.5255 - val_loss: 0.9793 - val_accuracy: 0.5636 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.8829 - accuracy: 0.6215 - val_loss: 0.7528 - val_accuracy: 0.6818 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7199 - accuracy: 0.7025 - val_loss: 0.6874 - val_accuracy: 0.6855 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6295 - accuracy: 0.7457 - val_loss: 0.5101 - val_accuracy: 0.8018 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5536 - accuracy: 0.7707 - val_loss: 0.4752 - val_accuracy: 0.8291 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4500 - accuracy: 0.8339 - val_loss: 0.4454 - val_accuracy: 0.8091 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4531 - accuracy: 0.8185 - val_loss: 0.5436 - val_accuracy: 0.8236 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4642 - accuracy: 0.8153 - val_loss: 0.4397 - val_accuracy: 0.8418 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3773 - accuracy: 0.8608 - val_loss: 0.4083 - val_accuracy: 0.8309 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3367 - accuracy: 0.8744 - val_loss: 0.2832 - val_accuracy: 0.9055 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3020 - accuracy: 0.8981 - val_loss: 0.3164 - val_accuracy: 0.8945 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2708 - accuracy: 0.9026 - val_loss: 0.2650 - val_accuracy: 0.9036 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2640 - accuracy: 0.9067 - val_loss: 0.3784 - val_accuracy: 0.8691 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2731 - accuracy: 0.9108 - val_loss: 0.4066 - val_accuracy: 0.8473 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3179 - accuracy: 0.8881 - val_loss: 0.2771 - val_accuracy: 0.9127 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2320 - accuracy: 0.9204 - val_loss: 0.2383 - val_accuracy: 0.9255 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2448 - accuracy: 0.9131 - val_loss: 0.3207 - val_accuracy: 0.8836 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1993 - accuracy: 0.9331 - val_loss: 0.2343 - val_accuracy: 0.9127 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1719 - accuracy: 0.9440 - val_loss: 0.2163 - val_accuracy: 0.9309 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1568 - accuracy: 0.9422 - val_loss: 0.2178 - val_accuracy: 0.9364 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1533 - accuracy: 0.9459 - val_loss: 0.2287 - val_accuracy: 0.9273 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1523 - accuracy: 0.9486 - val_loss: 0.3309 - val_accuracy: 0.9036 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1490 - accuracy: 0.9431 - val_loss: 0.2024 - val_accuracy: 0.9364 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1378 - accuracy: 0.9568 - val_loss: 0.2150 - val_accuracy: 0.9255 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1382 - accuracy: 0.9522 - val_loss: 0.4213 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1564 - accuracy: 0.9568 - val_loss: 0.2285 - val_accuracy: 0.9200 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1330 - accuracy: 0.9559 - val_loss: 0.1811 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1253 - accuracy: 0.9604 - val_loss: 0.2107 - val_accuracy: 0.9273 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1163 - accuracy: 0.9641 - val_loss: 0.2230 - val_accuracy: 0.9418 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1013 - accuracy: 0.9686 - val_loss: 0.1466 - val_accuracy: 0.9491 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0815 - accuracy: 0.9773 - val_loss: 0.1471 - val_accuracy: 0.9564 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0655 - accuracy: 0.9786 - val_loss: 0.1436 - val_accuracy: 0.9582 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0556 - accuracy: 0.9859 - val_loss: 0.1842 - val_accuracy: 0.9582 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0600 - accuracy: 0.9804 - val_loss: 0.1772 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0552 - accuracy: 0.9845 - val_loss: 0.1665 - val_accuracy: 0.9582 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0522 - accuracy: 0.9854 - val_loss: 0.1909 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0598 - accuracy: 0.9809 - val_loss: 0.1716 - val_accuracy: 0.9636 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0423 - accuracy: 0.9882 - val_loss: 0.1628 - val_accuracy: 0.9655 - lr: 2.0000e-04\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9868 - val_loss: 0.1493 - val_accuracy: 0.9673 - lr: 2.0000e-04\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9877 - val_loss: 0.1679 - val_accuracy: 0.9636 - lr: 2.0000e-04\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0379 - accuracy: 0.9886 - val_loss: 0.1458 - val_accuracy: 0.9636 - lr: 2.0000e-04\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 0.9854 - val_loss: 0.1634 - val_accuracy: 0.9618 - lr: 2.0000e-04\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9814\n",
      "Train Accuracy: 98.14%\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3923 - accuracy: 0.7688\n",
      "Test Accuracy: 76.88%\n",
      "86/86 [==============================] - 1s 2ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Gesture A       0.99      0.97      0.98       702\n",
      "   Gesture D       0.98      0.99      0.99       699\n",
      "   Gesture L       0.98      0.98      0.98       663\n",
      "   Gesture U       0.97      0.99      0.98       684\n",
      "\n",
      "    accuracy                           0.98      2748\n",
      "   macro avg       0.98      0.98      0.98      2748\n",
      "weighted avg       0.98      0.98      0.98      2748\n",
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Gesture A       0.76      0.93      0.83        40\n",
      "   Gesture D       0.79      0.95      0.86        40\n",
      "   Gesture L       0.82      0.57      0.68        40\n",
      "   Gesture U       0.71      0.62      0.67        40\n",
      "\n",
      "    accuracy                           0.77       160\n",
      "   macro avg       0.77      0.77      0.76       160\n",
      "weighted avg       0.77      0.77      0.76       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 数据增强\n",
    "train_X_scaled, train_y_one_hot = augment_data(train_X_scaled, train_y_one_hot)\n",
    "\n",
    "# 打乱数据\n",
    "train_X_scaled, train_y_one_hot = shuffle(train_X_scaled, train_y_one_hot)\n",
    "\n",
    "# 构建混合模型\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(train_X_scaled.shape[1], train_X_scaled.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(train_y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# 使用早停法和学习率调度器\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# 训练模型\n",
    "model.fit(train_X_scaled, train_y_one_hot, epochs=100, batch_size=128, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# 评估模型在训练集和验证集上的表现\n",
    "train_results = model.evaluate(train_X_scaled, train_y_one_hot)\n",
    "print(f\"Train Accuracy: {train_results[1] * 100:.2f}%\")\n",
    "\n",
    "# 评估模型在独立测试集上的表现\n",
    "test_results = model.evaluate(test_X_scaled, test_y_one_hot)\n",
    "print(f\"Test Accuracy: {test_results[1] * 100:.2f}%\")\n",
    "\n",
    "# 打印分类报告\n",
    "y_pred_train = model.predict(train_X_scaled)\n",
    "y_pred_test = model.predict(test_X_scaled)\n",
    "\n",
    "y_pred_train_classes = np.argmax(y_pred_train, axis=1)\n",
    "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "y_train_classes = np.argmax(train_y_one_hot, axis=1)\n",
    "y_test_classes = np.argmax(test_y_one_hot, axis=1)\n",
    "\n",
    "print(\"Classification Report (Train):\")\n",
    "print(classification_report(y_train_classes, y_pred_train_classes, target_names=label_encoder.classes_))\n",
    "\n",
    "print(\"Classification Report (Test):\")\n",
    "print(classification_report(y_test_classes, y_pred_test_classes, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('E:/TFM/gesture_modelCNNNORX.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yao20\\AppData\\Local\\Temp\\tmpoogenj9s\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yao20\\AppData\\Local\\Temp\\tmpoogenj9s\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yao20\\AppData\\Local\\Temp\\tmprl0jjy8n\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yao20\\AppData\\Local\\Temp\\tmprl0jjy8n\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Conversion Successful\n"
     ]
    }
   ],
   "source": [
    "# load keras model\n",
    "model = tf.keras.models.load_model('E:/TFM/gesture_modelCNNNORX.keras')\n",
    "\n",
    "# Converting models to TensorFlow Lite models\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Saving the converted model\n",
    "try:\n",
    "    tflite_model = converter.convert()\n",
    "    with open('E:/TFM/gesture_modelCNNNORX.tflite', 'wb') as f:\n",
    "       f.write(tflite_model)\n",
    "    print(\"Model Conversion Successful\")\n",
    "except Exception as e:\n",
    "    print(f\"Model conversion failure: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
